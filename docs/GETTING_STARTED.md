# ğŸ“ ChronicleLedger - Complete Project Walkthrough

> **Your Personal Guide**: Everything you need to understand, run, and showcase this project

---

## ğŸ“š Table of Contents

1. [Project Overview - What Did You Build?](#1-project-overview)
2. [Architecture Deep Dive - How Does It Work?](#2-architecture-deep-dive)
3. [Step-by-Step Startup Guide](#3-step-by-step-startup)
4. [Testing Every Feature](#4-testing-every-feature)
5. [What to Show Recruiters](#5-what-to-show-recruiters)
6. [Troubleshooting](#6-troubleshooting)

---

## 1. Project Overview - What Did You Build?

### ğŸ¯ **The Big Picture**

You built a **production-grade Event Sourcing system** - a banking ledger that:
- Never deletes data (append-only event log)
- Can query account balance at ANY point in history (time-travel!)
- Separates writes from reads (CQRS pattern)
- Uses modern distributed systems patterns

### ğŸ’¡ **Why This Matters to Recruiters**

This project proves you understand:
- âœ… **Advanced Architecture Patterns** (Event Sourcing + CQRS)
- âœ… **Distributed Systems** (eventual consistency, event-driven design)
- âœ… **Modern Full-Stack** (TypeScript, Node.js, Next.js)
- âœ… **System Design** (scalability, fault tolerance, audit compliance)

### ğŸ—ï¸ **Tech Stack**

| Layer | Technology | Purpose |
|:------|:-----------|:--------|
| **Event Store** | PostgreSQL | Immutable log of all events |
| **Read Database** | PostgreSQL | Fast queries (materialized views) |
| **Message Bus** | NATS | Pub/sub for event distribution |
| **Write API** | Node.js + Fastify | Handle commands (deposits, transfers) |
| **Query API** | Node.js + Fastify | Fast reads + time-travel queries |
| **Event Processor** | Node.js | Consumes events, updates read model |
| **Dashboard** | Next.js 14 | Real-time event viewer UI |

---

## 2. Architecture Deep Dive - How Does It Work?

### ğŸ”„ **The Event Sourcing Flow**

```
USER ACTION (Deposit $100)
    â†“
LEDGER API (Validate, Create Event)
    â†“
SAVE EVENT to PostgreSQL Event Store
    â†“
PUBLISH EVENT to NATS Message Bus
    â†“
READ PROCESSOR (NATS Consumer)
    â†“
UPDATE READ MODEL (PostgreSQL Materialized Views)
    â†“
QUERY API (Fast lookups from Read Model)
```

### ğŸ¯ **CQRS Pattern Explained**

**CQRS** = Command Query Responsibility Segregation

**Commands (Writes)** â†’ Ledger API â†’ Event Store
- POST /commands/create-account
- POST /commands/deposit
- POST /commands/withdraw
- POST /commands/transfer

**Queries (Reads)** â†’ Query API â†’ Read Model
- GET /accounts/:id
- GET /accounts/:id/balance-at?timestamp=X  â† **TIME TRAVEL!**
- GET /accounts/:id/transactions
- GET /events

### â° **Time-Travel Queries - The Star Feature**

**How it works**:
1. User asks: "What was account ACC-001's balance on Jan 1, 2026 at 10 AM?"
2. Query API fetches ALL events for ACC-001 **before** that timestamp
3. Replays events in order: Created â†’ Deposited â†’ Withdrawn â†’ Deposited
4. Returns the calculated balance at that exact moment

**Why it's powerful**:
- Debug issues: "Why did this account have negative balance last week?"
- Compliance: "Prove account state at time of audit"
- Analytics: "Show balance trends over time"

---

## 3. Step-by-Step Startup

### âœ… **Phase 1: Infrastructure (Already Running!)**

Check if Docker containers are running:
```powershell
docker ps
```

**What you should see**:
```
chronicle-db (PostgreSQL)   - Port 5433 - Healthy âœ“
chronicle-nats (NATS)       - Ports 4222/8222 - Healthy âœ“
```

**What these do**:
- `chronicle-db`: Stores BOTH event log AND read model (simplified setup)
- `chronicle-nats`: Message bus for event distribution

---

### âœ… **Phase 2: Install Dependencies**

```powershell
cd "g:\LearningRelated\Portfolio Project\chronicle-ledge"
npm install
```

**What this installs**:
- Root dependencies: `concurrently`, `pg`, `node-fetch`
- Ledger API: `fastify`, `@fastify/cors`, `uuid`, `nats`
- Query API: Same as Ledger API
- Read Processor: NATS client, PostgreSQL client
- Dashboard: Next.js, React, TypeScript

**Wait time**: ~2-3 minutes

---

### âœ… **Phase 3: Initialize Database Schema**

The database schema is already created via the init script in docker-compose!

**Verify it worked**:
```powershell
# Check if tables exist
docker exec -it chronicle-db psql -U chronicle -d chronicle -c "\dt"
```

**What you should see**:
- `events` table (event store)
- `account_balance` table (read model)
- `transactions` table (read model)

---

### âœ… **Phase 4: Start All Services**

```powershell
npm run dev
```

**What this starts** (all at once):
1. **Ledger API** - Port 4000 - Handles write commands
2. **Read Processor** - No port (NATS consumer) - Updates read model
3. **Query API** - Port 4001 - Handles read queries
4. **Dashboard** - Port 3000 - Web UI

**What you should see in terminal**:
```
[ledger-api] Server listening on http://0.0.0.0:4000
[ledger-api] Connected to PostgreSQL (Event Store)
[ledger-api] Connected to NATS
[query-api] Server listening on http://0.0.0.0:4001
[query-api] Connected to PostgreSQL (Read Model)
[read-processor] Connected to NATS
[read-processor] Subscribed to events.account.*
[dashboard] ready started server on 0.0.0.0:3000
```

---

## 4. Testing Every Feature

### ğŸ§ª **Test 1: Health Checks**

**What**: Verify all services are reachable
**Why**: Confirm infrastructure is working

```powershell
# Test Ledger API
curl http://localhost:4000/health

# Test Query API
curl http://localhost:4001/health
```

**Expected Response**:
```json
{"status":"ok","service":"ledger-api"}
{"status":"ok","service":"query-api"}
```

---

### ğŸ§ª **Test 2: Create an Account**

**What**: Create your first account
**Why**: This writes the first event to the system

```powershell
curl -X POST http://localhost:4000/commands/create-account `
  -H "Content-Type: application/json" `
  -d '{
    "account_id": "ACC-001",
    "owner_name": "Alice Johnson",
    "initial_balance": 1000,
    "currency": "USD"
  }'
```

**Expected Response**:
```json
{"success":true,"event_id":"<uuid>"}
```

**What just happened**:
1. âœ… Ledger API validated the command
2. âœ… Created `AccountCreated` event
3. âœ… Saved event to PostgreSQL `events` table
4. âœ… Published event to NATS topic `events.account.created`
5. âœ… Read Processor consumed event
6. âœ… Updated `account_balance` table with balance=1000

**Verify it worked**:
```powershell
# Query the account
curl http://localhost:4001/accounts/ACC-001
```

**Expected**:
```json
{
  "account_id": "ACC-001",
  "owner_name": "Alice Johnson",
  "balance": "1000.00",
  "currency": "USD"
}
```

---

### ğŸ§ª **Test 3: Deposit Money**

**What**: Add $500 to account
**Why**: Test event append and read model update

```powershell
curl -X POST http://localhost:4000/commands/deposit `
  -H "Content-Type: application/json" `
  -d '{
    "account_id": "ACC-001",
    "amount": 500,
    "description": "Salary payment"
  }'
```

**What happens**:
- Event: `MoneyDeposited` with amount=500
- Read Model: `balance` updates from 1000 â†’ 1500

**Verify**:
```powershell
curl http://localhost:4001/accounts/ACC-001
# Should show balance: 1500.00
```

---

### ğŸ§ª **Test 4: Transfer Between Accounts**

**What**: Create second account, transfer money
**Why**: Tests atomic multi-event transactions

```powershell
# Create second account
curl -X POST http://localhost:4000/commands/create-account `
  -H "Content-Type: application/json" `
  -d '{
    "account_id": "ACC-002",
    "owner_name": "Bob Smith",
    "initial_balance": 500,
    "currency": "USD"
  }'

# Transfer $200 from Alice to Bob
curl -X POST http://localhost:4000/commands/transfer `
  -H "Content-Type: application/json" `
  -d '{
    "from_account_id": "ACC-001",
    "to_account_id": "ACC-002",
    "amount": 200,
    "description": "Payment for services"
  }'
```

**What happens**:
- 2 events created: `MoneyWithdrawn` (ACC-001) + `MoneyDeposited` (ACC-002)
- Both events have same `transfer_id` for linking
- Read Model updates BOTH balances

**Verify**:
```powershell
curl http://localhost:4001/accounts/ACC-001  # Should be 1300
curl http://localhost:4001/accounts/ACC-002  # Should be 700
```

---

### ğŸ§ª **Test 5: Time-Travel Query** â­

**What**: Query historical balance
**Why**: This is the COOLEST feature - shows Event Sourcing power!

```powershell
# First, note the current time
$timestamp = (Get-Date).ToUniversalTime().ToString("yyyy-MM-ddTHH:mm:ssZ")

# Do another deposit
curl -X POST http://localhost:4000/commands/deposit `
  -H "Content-Type: application/json" `
  -d '{"account_id":"ACC-001","amount":100,"description":"Bonus"}'

# Current balance
curl http://localhost:4001/accounts/ACC-001
# Should show 1400

# Balance BEFORE the last deposit (use the timestamp from above)
curl "http://localhost:4001/accounts/ACC-001/balance-at?timestamp=$timestamp"
# Should show 1300 (the balance BEFORE the deposit!)
```

**Why this is impressive**:
- No snapshots needed!
- Query ANY point in history
- Perfect audit trail
- Compliance-ready

---

### ğŸ§ª **Test 6: View Event Log**

**What**: See ALL events in the system
**Why**: Complete audit trail

```powershell
curl http://localhost:4001/events?limit=50
```

**What you'll see**:
```json
{
  "events": [
    {
      "event_id": "...",
      "aggregate_id": "ACC-001",
      "event_type": "MoneyDeposited",
      "event_data": {"amount": 100, "description": "Bonus"},
      "created_at": "2026-01-04T15:15:30Z"
    },
    {
      "event_type": "MoneyDeposited",
      "event_data": {"amount": 200, "transfer_id": "..."}
    },
    ...
  ]
}
```

---

### ğŸ§ª **Test 7: Dashboard UI**

**What**: Visual interface
**Why**: Easier to explore than curl commands

**Open in browser**:
```
http://localhost:3000
```

**What you'll see**:
- Real-time event stream (auto-refreshes every 2 seconds)
- Filter events by type
- Expandable JSON details
- Copy-to-clipboard functionality

---

### ğŸ§ª **Test 8: Automated E2E Test**

**What**: Run the full test suite
**Why**: Tests all features at once

```powershell
node scripts/e2e-test.js
```

**What it tests**:
1. âœ… Create account
2. âœ… Deposit money
3. âœ… Transfer between accounts
4. âœ… Withdraw money
5. âœ… Time-travel query
6. âœ… Event log retrieval

**Expected output**:
```
âœ… Account created successfully
âœ… Deposit successful
âœ… Transfer successful
âœ… Withdrawal successful
âœ… Time-travel query successful
âœ… All tests passed!
```

---

## 5. What to Show Recruiters

### ğŸ“¸ **Demo Flow for Interviews**

**1. Start with the "Why"** (30 seconds)
> "This project demonstrates Event Sourcing and CQRS - patterns used by companies like Uber and Netflix for systems that need complete audit trails and time-travel debugging."

**2. Show the Architecture Diagram** (1 minute)
- Open `docs/HLD.md`
- Explain: Write path (commands) vs Read path (queries)
- Highlight: NATS for async event distribution

**3. Live Demo** (3 minutes)
```powershell
# Show services running
docker ps
Get-Process | Where-Object {$_.ProcessName -like "*node*"}

# Create account and show immediate query
curl -X POST http://localhost:4000/commands/create-account ...
curl http://localhost:4001/accounts/ACC-001

# Time-travel demo
curl "http://localhost:4001/accounts/ACC-001/balance-at?timestamp=..."
```

**4. Show the Code** (2 minutes)
- **Event Creation**: `services/ledger-api/src/index.ts` (lines 25-66)
- **Event Replay**: `services/query-api/src/index.ts` (lines 51-88)
- **Event Processing**: `services/read-processor/src/index.ts`

**5. Explain Trade-offs** (1 minute)
> "Event Sourcing gives us complete audit history and time-travel, but adds complexity - we need to maintain two data models and handle eventual consistency. I chose this pattern because audit compliance was a key requirement."

---

### ğŸ’¬ **Key Talking Points**

âœ… **Event Sourcing**: "Instead of UPDATE statements, we only INSERT events. The current state is derived by replaying all events."

âœ… **CQRS**: "Writes go to one optimized path (event store), reads go to another (materialized views). This separates concerns and scales independently."

âœ… **Time-Travel**: "By replaying events up to a specific timestamp, we can query historical state without storing snapshots."

âœ… **Distributed Systems**: "Originally designed for CockroachDB (distributed database), simplified to PostgreSQL but the patterns remain the same."

âœ… **Production Ready**: "Includes health checks, error handling, idempotency design, and comprehensive documentation."

---

## 6. Troubleshooting

### âŒ **Problem**: Services won't start - "concurrently: command not found"
**Solution**:
```powershell
npm install
# Wait for installation to complete, then:
npm run dev
```

---

### âŒ **Problem**: Docker containers not running
**Solution**:
```powershell
docker-compose up -d
# Wait 10 seconds for health checks
docker ps
```

---

### âŒ **Problem**: "Cannot connect to PostgreSQL"
**Solution**:
```powershell
# Check if container is healthy
docker ps
# If unhealthy, restart
docker-compose restart postgres
# Wait 10 seconds
docker exec -it chronicle-db pg_isready -U chronicle
```

---

### âŒ **Problem**: Transfer fails with "Insufficient funds"
**Solution**: This is CORRECT behavior! Event Sourcing validates business rules. Check current balance first:
```powershell
curl http://localhost:4001/accounts/ACC-001
```

---

### âŒ **Problem**: Read Model is out of sync with Event Store
**Solution**: Run consistency check:
```powershell
node scripts/verify-consistency.js
```

---

## ğŸ“ **Understanding Your Code**

### ğŸ“‚ **Project Structure**

```
chronicle-ledge/
â”œâ”€â”€ docker-compose.yml          â† Infrastructure definition
â”œâ”€â”€ package.json                â† Workspace root
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ ledger-api/            â† Write service (commands)
â”‚   â”‚   â””â”€â”€ src/
â”‚   â”‚       â”œâ”€â”€ index.ts       â† Main API (326 lines)
â”‚   â”‚       â”œâ”€â”€ db.ts          â† PostgreSQL connection
â”‚   â”‚       â””â”€â”€ nats.ts        â† NATS publisher
â”‚   â”œâ”€â”€ query-api/             â† Read service (queries)
â”‚   â”‚   â””â”€â”€ src/
â”‚   â”‚       â”œâ”€â”€ index.ts       â† Query endpoints + time-travel
â”‚   â”‚       â”œâ”€â”€ db.ts          â† Read model connection
â”‚   â”‚       â””â”€â”€ eventStore.ts  â† Event store connection
â”‚   â””â”€â”€ read-processor/        â† Event consumer
â”‚       â””â”€â”€ src/
â”‚           â””â”€â”€ index.ts       â† NATS subscriber + view updater
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ dashboard/             â† Next.js UI
â”‚       â””â”€â”€ src/
â”‚           â””â”€â”€ app/
â”‚               â””â”€â”€ page.tsx   â† Event log viewer
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ e2e-test.js           â† Automated test suite
â”‚   â”œâ”€â”€ simulate-traffic.js   â† Load generator
â”‚   â””â”€â”€ verify-consistency.js â† Data validation
â””â”€â”€ docs/
    â”œâ”€â”€ HLD.md                 â† Architecture diagrams
    â”œâ”€â”€ LLD.md                 â† API contracts
    â”œâ”€â”€ EVENT_SOURCING.md      â† Pattern explanation
    â”œâ”€â”€ FAILURE_SCENARIOS.md   â† Chaos testing
    â””â”€â”€ INTERVIEW.md           â† Q&A prep (30+ questions)
```

---

### ğŸ”‘ **Key Code Sections**

#### **1. Event Creation (Ledger API)**
**File**: `services/ledger-api/src/index.ts:33-66`

```typescript
// Validate command
if (!account_id || !owner_name) {
  return reply.status(400).send({ error: 'Missing fields' });
}

// Create event object
const event = {
  event_id: uuidv4(),
  aggregate_id: account_id,
  event_type: 'AccountCreated',
  event_data: { owner_name, initial_balance, currency },
  created_at: new Date().toISOString()
};

// Persist to event store
await query('INSERT INTO events (...) VALUES (...)', [...]);

// Publish to NATS
await publishEvent('events.account.created', event);
```

**Why this matters**: Demonstrates event-driven write path with persistence + messaging.

---

#### **2. Time-Travel Query (Query API)**
**File**: `services/query-api/src/index.ts:51-88`

```typescript
// Fetch all events BEFORE the timestamp
const res = await queryEvents(
  'SELECT event_type, event_data FROM events WHERE aggregate_id = $1 AND created_at <= $2 ORDER BY created_at ASC',
  [id, timestamp]
);

let balance = 0;
// Replay events in order
for (const row of res.rows) {
  if (row.event_type.includes('Created')) {
    balance = parseFloat(data.initial_balance);
  } else if (row.event_type.includes('Deposited')) {
    balance += parseFloat(data.amount);
  } else if (row.event_type.includes('Withdrawn')) {
    balance -= parseFloat(data.amount);
  }
}

return { account_id: id, balance, at: timestamp };
```

**Why this matters**: Shows event replay for state reconstruction - the CORE of Event Sourcing.

---

#### **3. Event Consumer (Read Processor)**
**File**: `services/read-processor/src/index.ts`

```typescript
// Subscribe to all account events
await nc.subscribe('events.account.*', {
  async callback(err, msg) {
    const event = JSON.parse(msg.data);
    
    // Update read model based on event type
    if (event.event_type === 'AccountCreated') {
      await query('INSERT INTO account_balance ...');
    } else if (event.event_type === 'MoneyDeposited') {
      await query('UPDATE account_balance SET balance = balance + $1 ...');
    }
  }
});
```

**Why this matters**: Demonstrates eventual consistency and materialized view pattern.

---

## ğŸ¯ **Learning Outcomes**

After completing this walkthrough, you now understand:

âœ… **Event Sourcing**: Append-only log, state from events  
âœ… **CQRS**: Separate read/write models  
âœ… **Time-Travel**: Event replay for historical queries  
âœ… **Event-Driven Architecture**: NATS pub/sub  
âœ… **Distributed Patterns**: Eventual consistency  
âœ… **Modern Full-Stack**: TypeScript, Node.js, Next.js  
âœ… **Docker Orchestration**: Multi-container setup  
âœ… **System Design**: Scalability, fault tolerance, audit compliance  

---

## ğŸš€ **Next Steps**

1. **Run the project** using this guide
2. **Take screenshots** of:
   - Architecture diagram from docs/HLD.md
   - Terminal showing all services running
   - Dashboard UI at localhost:3000
   - Time-travel query result
3. **Record a demo video** (2-3 minutes)
4. **Update your resume** with:
   - "Built event-sourced banking system with time-travel queries"
   - "Implemented CQRS pattern with Node.js and PostgreSQL"
   - "Designed distributed architecture with NATS messaging"

---

## ğŸ“ **Questions for Interviews**

Be ready to answer:

1. **"Why Event Sourcing over traditional CRUD?"**
   > "Event Sourcing provides a complete audit trail, time-travel debugging, and makes it impossible to lose data since we never delete. The tradeoff is increased complexity in maintaining two data models."

2. **"How do you handle eventual consistency?"**
   > "The read model updates asynchronously via NATS events. In production, I would add idempotency keys and retry logic. For critical reads, I'd allow clients to query the event store directly for strong consistency."

3. **"How does this scale?"**
   > "The write path (Ledger API) scales horizontally - each instance writes to the same event store. The read path scales independently - we can add read replicas. NATS handles event distribution across multiple consumers."

---

**Built with**: Event Sourcing â€¢ CQRS â€¢ PostgreSQL â€¢ NATS â€¢ Next.js  
**Author**: Harshan Aiyappa  
**Purpose**: Portfolio project demonstrating senior-level distributed systems knowledge
